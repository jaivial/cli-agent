Trial llm-inference-batching-scheduler__3vU7AHt failed: Docker compose command failed for environment llm-inference-batching-scheduler. Command: docker compose -p llm-inference-batching-scheduler__3vu7aht -f /Users/usuario/Desktop/cli-agent/harbor_env/lib/python3.14/site-packages/harbor/environments/docker/docker-compose-prebuilt.yaml up -d. Return code: 1. Stdout: unable to get image 'alexgshaw/llm-inference-batching-scheduler:20251031': Cannot connect to the Docker daemon at unix:///Users/usuario/.docker/run/docker.sock. Is the docker daemon running?
. Stderr: None. 
Docker compose down failed: Docker compose command failed for environment llm-inference-batching-scheduler. Command: docker compose -p llm-inference-batching-scheduler__3vu7aht -f /Users/usuario/Desktop/cli-agent/harbor_env/lib/python3.14/site-packages/harbor/environments/docker/docker-compose-prebuilt.yaml down --rmi all --volumes --remove-orphans. Return code: 1. Stdout: Cannot connect to the Docker daemon at unix:///Users/usuario/.docker/run/docker.sock. Is the docker daemon running?
. Stderr: None. 

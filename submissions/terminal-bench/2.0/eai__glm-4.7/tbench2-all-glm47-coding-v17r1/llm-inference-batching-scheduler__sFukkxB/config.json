{
    "task": {
        "path": "llm-inference-batching-scheduler",
        "git_url": "https://github.com/laude-institute/terminal-bench-2.git",
        "git_commit_id": "69671fbaac6d67a7ef0dfec016cc38a64ef7a77c",
        "overwrite": false,
        "download_dir": null,
        "source": "terminal-bench"
    },
    "trial_name": "llm-inference-batching-scheduler__sFukkxB",
    "trials_dir": "jobs/tbench2-all-glm47-coding-v17r1",
    "timeout_multiplier": 1.0,
    "agent": {
        "name": null,
        "import_path": "eai_agent.agent:EaiAgent",
        "model_name": null,
        "override_timeout_sec": null,
        "override_setup_timeout_sec": null,
        "max_timeout_sec": null,
        "kwargs": {
            "max_loops": 60,
            "base_url": "https://api.z.ai/api/coding/paas/v4/chat/completions",
            "model": "glm-4.7",
            "max_tokens": 4096
        }
    },
    "environment": {
        "type": "docker",
        "import_path": null,
        "force_build": false,
        "delete": false,
        "override_cpus": null,
        "override_memory_mb": null,
        "override_storage_mb": null,
        "override_gpus": null,
        "suppress_override_warnings": false,
        "kwargs": {}
    },
    "verifier": {
        "override_timeout_sec": null,
        "max_timeout_sec": null,
        "disable": false
    },
    "job_id": "6f7102f0-1e49-4769-8ba4-abe7ee374ce6"
}